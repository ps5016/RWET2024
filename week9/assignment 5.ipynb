{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ef18008e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.7.4\n",
      "  latest version: 24.3.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=24.3.0\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!conda install --prefix {sys.prefix} -y -c pytorch pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59bf7a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/pien/anaconda3/lib/python3.11/site-packages (4.32.1)\n",
      "Requirement already satisfied: filelock in /Users/pien/anaconda3/lib/python3.11/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /Users/pien/anaconda3/lib/python3.11/site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/pien/anaconda3/lib/python3.11/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/pien/anaconda3/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/pien/anaconda3/lib/python3.11/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/pien/anaconda3/lib/python3.11/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in /Users/pien/anaconda3/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/pien/anaconda3/lib/python3.11/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/pien/anaconda3/lib/python3.11/site-packages (from transformers) (0.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/pien/anaconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /Users/pien/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/pien/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/pien/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/pien/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pien/anaconda3/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/pien/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bcb99c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pien/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3460d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('distilgpt2')\n",
    "model = AutoModelForCausalLM.from_pretrained('distilgpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5572d559",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline('text-generation', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc81b394",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"eight of pentacles.\\n\\u200dA couple of years ago a new paper published in the Journal of Geophysical Research suggested that the solar wind's high wind speed and low wind speed may explain why solar wind power remains so popular. For example,\"}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"eight of pentacles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa3db003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: tracery in /Users/pien/anaconda3/lib/python3.11/site-packages (0.1.1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install tracery\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9d8b1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tracery\n",
    "from tracery.modifiers import base_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24438038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: markovify in /Users/pien/anaconda3/lib/python3.11/site-packages (0.9.4)\n",
      "Requirement already satisfied: unidecode in /Users/pien/anaconda3/lib/python3.11/site-packages (from markovify) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install markovify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3f8b6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline('text-generation', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1587830",
   "metadata": {},
   "outputs": [],
   "source": [
    "cards = [\n",
    "    \"The Fool\", \"The Magician\", \"The High Priestess\", \"The Empress\", \"The Emperor\", \"The Hierophant\", \"The Lovers\", \"The Chariot\", \"Strength\", \"The Hermit\", \"Wheel of Fortune\", \"Justice\", \"The Hanged Man\", \"Death\", \"Temperance\", \"The Devil\", \"The Tower\", \"The Star\", \"The Moon\", \"The Sun\", \"Judgment\", \"The World\", \"Ace of Wands\", \"Two of Wands\", \"Three of Wands\", \"Four of Wands\", \"Five of Wands\", \"Six of Wands\", \"Seven of Wands\", \"Eight of Wands\", \"Nine of Wands\", \"Ten of Wands\", \"Page of Wands\", \"Knight of Wands\", \"Queen of Wands\", \"King of Wands\", \"Ace of Cups\", \"Two of Cups\", \"Three of Cups\", \"Four of Cups\", \"Five of Cups\", \"Six of Cups\", \"Seven of Cups\", \"Eight of Cups\", \"Nine of Cups\", \"Ten of Cups\", \"Page of Cups\", \"Knight of Cups\", \"Queen of Cups\", \"King of Cups\", \"Ace of Swords\", \"Two of Swords\", \"Three of Swords\", \"Four of Swords\", \"Five of Swords\", \"Six of Swords\", \"Seven of Swords\", \"Eight of Swords\", \"Nine of Swords\", \"Ten of Swords\", \"Page of Swords\", \"Knight of Swords\", \"Queen of Swords\", \"King of Swords\", \"Ace of Pentacles\", \"Two of Pentacles\", \"Three of Pentacles\", \"Four of Pentacles\", \"Five of Pentacles\", \"Six of Pentacles\", \"Seven of Pentacles\", \"Eight of Pentacles\", \"Nine of Pentacles\", \"Ten of Pentacles\", \"Page of Pentacles\", \"Knight of Pentacles\", \"Queen of Pentacles\", \"King of Pentacles\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164a1c52",
   "metadata": {},
   "source": [
    "# model = AutoModelForCausalLM.from_pretrained('distilgpt2') #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2fc6e71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tarot of the Day ìÜè„Äö Justice „Äõ\n",
      " \n",
      "‚òÖ Your Tarot Reader ‚òÖ AutoModelForCausalLM, AutoTokenizer ‚òÖ\n",
      "\n",
      "„Äö Justice „Äõ Justice „Äõ „Äõ Justice „Äõ Justice „Äõ Justice „Äõ Justice „Äõ Justice „Äõ Justice „Äõ Justice „Äõ Justice „Äõ Justice „Äõ Justice „Äõ Justice „Äõ Justice „Äõ Justice „Äõ Justice „Äõ Justice „Äõ Justice „Äõ Justice „Äõ Justice „Äõ Hiding The Court Acknowledge Judge's Right to Appeal Justices Sides First\n",
      "\n",
      "The Supreme Court has a majority in the case of the Court of Appeals to the U.S. Circuit, and to the United States Supreme Court.\n",
      "In this opinion (2011), the majority held that judicial intervention in the cases\n",
      " \n"
     ]
    }
   ],
   "source": [
    "rules = {\n",
    "    \"origin\": \"#card#\",\n",
    "    \"card\": cards\n",
    "}\n",
    "grammar = tracery.Grammar(rules)\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "for i in range(1):\n",
    "    tarot_reading = grammar.flatten('„Äö #origin# „Äõ')\n",
    "    \n",
    "    generated_text = generator(tarot_reading, max_length=150)[0]['generated_text']\n",
    "    \n",
    "    print(f\"Tarot of the Day ìÜè{tarot_reading}\")\n",
    "    print(f\" \")\n",
    "    print(f\"‚òÖ Your Tarot Reader ‚òÖ AutoModelForCausalLM, AutoTokenizer ‚òÖ\\n\")\n",
    "    print(f\"{generated_text}\\n \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2d37da",
   "metadata": {},
   "source": [
    "# model=\"gpt2\" #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab61b6f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tarot of the Day ìÜè„Äö The Devil „Äõ\n",
      " \n",
      "‚òÖ Your Tarot Reader ‚òÖ gpt2 ‚òÖ\n",
      "\n",
      "„Äö The Devil „Äõ\n",
      " \n"
     ]
    }
   ],
   "source": [
    "rules = {\n",
    "    \"origin\": \"#card#\",\n",
    "    \"card\": cards\n",
    "}\n",
    "grammar = tracery.Grammar(rules)\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "for i in range(1):\n",
    "    tarot_reading = grammar.flatten('„Äö #origin# „Äõ')\n",
    "    \n",
    "    generated_text = generator(tarot_reading, max_length=150)[0]['generated_text']\n",
    "    \n",
    "    print(f\"Tarot of the Day ìÜè{tarot_reading}\")\n",
    "    print(f\" \")\n",
    "    print(f\"‚òÖ Your Tarot Reader ‚òÖ gpt2 ‚òÖ\\n\")\n",
    "    print(f\"{generated_text}\\n \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c6556c",
   "metadata": {},
   "source": [
    "# markovify #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1019dc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import markovify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d02d3cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tarot of the Day ìÜè„ÄöPage of Pentacles„Äõ\n",
      " \n",
      "‚òÖ Your Tarot Reader ‚òÖ Holden Caulfield ‚òÖ\n",
      "\n",
      "„ÄöPage of Pentacles„Äõ I nearly broke my neck and choke him to it--she holds up her mother in this very long peaks.\n",
      " \n"
     ]
    }
   ],
   "source": [
    "with open(\"thecatcherintherye.txt\") as f:\n",
    "    tarot_readings_text = f.read()\n",
    "\n",
    "text_model = markovify.Text(tarot_readings_text)\n",
    "\n",
    "rules = {\n",
    "    \"origin\": \"#card#\",\n",
    "    \"card\": cards\n",
    "}\n",
    "grammar = tracery.Grammar(rules)\n",
    "\n",
    "for i in range(1):\n",
    "    tarot_reading = grammar.flatten('„Äö#origin#„Äõ')    \n",
    "\n",
    "    generated_text = tarot_reading + \" \" + text_model.make_sentence()\n",
    "\n",
    "    print(f\"Tarot of the Day ìÜè{tarot_reading}\")\n",
    "    print(f\" \")\n",
    "    print(f\"‚òÖ Your Tarot Reader ‚òÖ Holden Caulfield ‚òÖ\\n\")\n",
    "    print(f\"{generated_text}\\n \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f57a4ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0476ace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
