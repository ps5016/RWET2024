{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ef18008e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.7.4\n",
      "  latest version: 24.3.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=24.3.0\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!conda install --prefix {sys.prefix} -y -c pytorch pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "59bf7a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: transformers in /Users/pien/anaconda3/lib/python3.11/site-packages (4.32.1)\n",
      "Requirement already satisfied: filelock in /Users/pien/anaconda3/lib/python3.11/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /Users/pien/anaconda3/lib/python3.11/site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/pien/anaconda3/lib/python3.11/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/pien/anaconda3/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/pien/anaconda3/lib/python3.11/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/pien/anaconda3/lib/python3.11/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in /Users/pien/anaconda3/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/pien/anaconda3/lib/python3.11/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/pien/anaconda3/lib/python3.11/site-packages (from transformers) (0.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/pien/anaconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /Users/pien/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/pien/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/pien/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/pien/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pien/anaconda3/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/pien/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "1bcb99c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "c3460d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('distilgpt2')\n",
    "model = AutoModelForCausalLM.from_pretrained('distilgpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5572d559",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline('text-generation', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "bc81b394",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'eight of pentacles, or if pentacles were used on both of those devices to perform the tasks in the pentacle form or in the pentacle form. We also use several methods to verify or validate any of these claims, including making these known'}]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"eight of pentacles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "fa3db003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: tracery in /Users/pien/anaconda3/lib/python3.11/site-packages (0.1.1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install tracery\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c9d8b1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tracery\n",
    "from tracery.modifiers import base_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "24438038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: markovify in /Users/pien/anaconda3/lib/python3.11/site-packages (0.9.4)\n",
      "Requirement already satisfied: unidecode in /Users/pien/anaconda3/lib/python3.11/site-packages (from markovify) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install markovify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "d3f8b6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline('text-generation', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a1587830",
   "metadata": {},
   "outputs": [],
   "source": [
    "cards = [\n",
    "    \"The Fool\", \"The Magician\", \"The High Priestess\", \"The Empress\", \"The Emperor\", \"The Hierophant\", \"The Lovers\", \"The Chariot\", \"Strength\", \"The Hermit\", \"Wheel of Fortune\", \"Justice\", \"The Hanged Man\", \"Death\", \"Temperance\", \"The Devil\", \"The Tower\", \"The Star\", \"The Moon\", \"The Sun\", \"Judgment\", \"The World\", \"Ace of Wands\", \"Two of Wands\", \"Three of Wands\", \"Four of Wands\", \"Five of Wands\", \"Six of Wands\", \"Seven of Wands\", \"Eight of Wands\", \"Nine of Wands\", \"Ten of Wands\", \"Page of Wands\", \"Knight of Wands\", \"Queen of Wands\", \"King of Wands\", \"Ace of Cups\", \"Two of Cups\", \"Three of Cups\", \"Four of Cups\", \"Five of Cups\", \"Six of Cups\", \"Seven of Cups\", \"Eight of Cups\", \"Nine of Cups\", \"Ten of Cups\", \"Page of Cups\", \"Knight of Cups\", \"Queen of Cups\", \"King of Cups\", \"Ace of Swords\", \"Two of Swords\", \"Three of Swords\", \"Four of Swords\", \"Five of Swords\", \"Six of Swords\", \"Seven of Swords\", \"Eight of Swords\", \"Nine of Swords\", \"Ten of Swords\", \"Page of Swords\", \"Knight of Swords\", \"Queen of Swords\", \"King of Swords\", \"Ace of Pentacles\", \"Two of Pentacles\", \"Three of Pentacles\", \"Four of Pentacles\", \"Five of Pentacles\", \"Six of Pentacles\", \"Seven of Pentacles\", \"Eight of Pentacles\", \"Nine of Pentacles\", \"Ten of Pentacles\", \"Page of Pentacles\", \"Knight of Pentacles\", \"Queen of Pentacles\", \"King of Pentacles\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164a1c52",
   "metadata": {},
   "source": [
    "# model = AutoModelForCausalLM.from_pretrained('distilgpt2') #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c2fc6e71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tarot of the Day ìÜè„Äö Ten of Wands „Äõ\n",
      " \n",
      "‚òÖ Your Tarot Reader ‚òÖ AutoModelForCausalLM, AutoTokenizer ‚òÖ\n",
      "\n",
      "„Äö Ten of Wands „Äõ Ten of Y‚Ä¨ Ten of Y: Gai, who has not yet been able to meet himself, so he must join her. It seems that he is unable to deal with him so now.\n",
      "\n",
      "\"It's strange, though, that he can think that he did not want to leave in order to meet her until at present.\"\n",
      "\"I've known her the past three months, and when she has come back, she must have been there with her first wish. I hope she knows who she is.\"\n",
      "The next time the pair are at home, the entire world will be a bit different, though he will have to see her. He does not want to leave. He\n",
      " \n"
     ]
    }
   ],
   "source": [
    "rules = {\n",
    "    \"origin\": \"#card#\",\n",
    "    \"card\": cards\n",
    "}\n",
    "grammar = tracery.Grammar(rules)\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "for i in range(1):\n",
    "    tarot_reading = grammar.flatten('„Äö #origin# „Äõ')\n",
    "    \n",
    "    generated_text = generator(tarot_reading, max_length=150)[0]['generated_text']\n",
    "    \n",
    "    print(f\"Tarot of the Day ìÜè{tarot_reading}\")\n",
    "    print(f\" \")\n",
    "    print(f\"‚òÖ Your Tarot Reader ‚òÖ AutoModelForCausalLM, AutoTokenizer ‚òÖ\\n\")\n",
    "    print(f\"{generated_text}\\n \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2d37da",
   "metadata": {},
   "source": [
    "# model=\"gpt2\" #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ab61b6f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tarot of the Day ìÜè„Äö The Hanged Man „Äõ\n",
      " \n",
      "„Äö The Hanged Man „Äõ¬†,¬†(I'm a zombie, so just shoot at them.)\n",
      "\n",
      "\n",
      "But that's it. This is where they were the first, and by far the most dangerous.\n",
      "\n",
      "\n",
      "At the end of the second cycle, a single zombie with a powerful bite could easily kill your team members if they were not careful.\n",
      "\n",
      "\n",
      "After the first (not that scary) cycle of attacks, the Hanged Man has grown in strength and even more so in potency.\n",
      "\n",
      "\n",
      "After the fourth cycle, his toughness has increased by about half.\n",
      "\n",
      "\n",
      "When the fourth cycle completes, the Hanged Man has acquired a new kind of attack pattern: the \"Wrecker\"...\n",
      "\n",
      "\n",
      "In its\n",
      " \n"
     ]
    }
   ],
   "source": [
    "rules = {\n",
    "    \"origin\": \"#card#\",\n",
    "    \"card\": cards\n",
    "}\n",
    "grammar = tracery.Grammar(rules)\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "for i in range(1):\n",
    "    tarot_reading = grammar.flatten('„Äö #origin# „Äõ')\n",
    "    \n",
    "    generated_text = generator(tarot_reading, max_length=150)[0]['generated_text']\n",
    "    \n",
    "    print(f\"Tarot of the Day ìÜè{tarot_reading}\")\n",
    "    print(f\" \")\n",
    "    print(f\"‚òÖ Your Tarot Reader ‚òÖ gpt2 ‚òÖ\\n\")\n",
    "    print(f\"{generated_text}\\n \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c6556c",
   "metadata": {},
   "source": [
    "# markovify #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1019dc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import markovify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1f1e7e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tarot of the Day ìÜè„ÄöTwo of Swords„Äõ\n",
      " \n",
      "‚òÖ Your Tarot Reader ‚òÖ Holden Caulfield ‚òÖ\n",
      "\n",
      "„ÄöTwo of Swords„Äõ It hasn't got a ranch in Colorado.\n",
      " \n"
     ]
    }
   ],
   "source": [
    "with open(\"thecatcherintherye.txt\") as f:\n",
    "    tarot_readings_text = f.read()\n",
    "\n",
    "text_model = markovify.Text(tarot_readings_text)\n",
    "\n",
    "rules = {\n",
    "    \"origin\": \"#card#\",\n",
    "    \"card\": cards\n",
    "}\n",
    "grammar = tracery.Grammar(rules)\n",
    "\n",
    "for i in range(1):\n",
    "    tarot_reading = grammar.flatten('„Äö#origin#„Äõ')    \n",
    "\n",
    "    generated_text = tarot_reading + \" \" + text_model.make_sentence()\n",
    "\n",
    "    print(f\"Tarot of the Day ìÜè{tarot_reading}\")\n",
    "    print(f\" \")\n",
    "    print(f\"‚òÖ Your Tarot Reader ‚òÖ Holden Caulfield ‚òÖ\\n\")\n",
    "    print(f\"{generated_text}\\n \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f57a4ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
