{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6049b45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29c06e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75131cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec(s):\n",
    "    return nlp.vocab[s].vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4888b5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'width': 300,\n",
       " 'vectors': 20000,\n",
       " 'keys': 514157,\n",
       " 'name': 'en_vectors',\n",
       " 'mode': 'default'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.meta['vectors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7d59d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  898k  100  898k    0     0  4677k      0 --:--:-- --:--:-- --:--:-- 4703k\n"
     ]
    }
   ],
   "source": [
    "!curl -L -O https://raw.githubusercontent.com/aparrish/wordfreq-en-25000/main/wordfreq-en-25000-log.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9ea00ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "prob_lookup = dict(json.load(open(\"./wordfreq-en-25000-log.json\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0cbd1a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.7108"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_lookup['me']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ec57085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.7.4\n",
      "  latest version: 24.1.2\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=24.1.2\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!conda install -c conda-forge -y --prefix {sys.prefix} spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c26f3058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpleneighbors import SimpleNeighbors \n",
    "\n",
    "lookup = SimpleNeighbors(300)\n",
    "for word in prob_lookup.keys():\n",
    "    if nlp.vocab[word].has_vector:\n",
    "        lookup.add_one(word, vec(word))\n",
    "lookup.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe3d42ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['basketball',\n",
       " 'kano',\n",
       " 'soccer',\n",
       " 'volleyball',\n",
       " 'football',\n",
       " 'footy',\n",
       " 'softball',\n",
       " 'lacrosse',\n",
       " 'baseball',\n",
       " 'hockey',\n",
       " 'athletics',\n",
       " 'athletic']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup.nearest(vec('basketball'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3c45f5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['flower',\n",
       " 'daisy',\n",
       " 'lotus',\n",
       " 'sunflower',\n",
       " 'orchid',\n",
       " 'flowers',\n",
       " 'moses',\n",
       " 'roses',\n",
       " 'lily',\n",
       " 'rosen',\n",
       " 'bouquet',\n",
       " 'rosetta']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup.nearest(vec('flower'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c4630180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['champagne',\n",
       " 'caviar',\n",
       " 'cartier',\n",
       " 'gourmet',\n",
       " 'beer',\n",
       " 'ale',\n",
       " 'pint',\n",
       " 'mead',\n",
       " 'lager',\n",
       " 'keg',\n",
       " 'malta',\n",
       " 'whisky']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup.nearest(vec(\"wine\") - vec(\"alcohol\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dae49813",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will love you with no regard to the actions of our enemies or the jealousies of actors.\n",
      " I will love you with no regard to the outrage of certain parents or the boredom of certain friends.\n",
      " I will love you no matter what is served in the worldâ€™s cafeterias or what game is played at each and every recess.\n",
      " I will love you no matter how many fire drills we are all forced to endure, and no matter what is drawn upon the blackboard in a blurring, boring chalk.\n",
      " I will love you no matter how many mistakes I make when trying to reduce fractions, and no matter how difficult it is to memorize the periodic table.\n",
      " I will love you no matter what your locker combination was, or how you decided to spend your time during study hall.\n",
      " I will love you no matter how your soccer team performed in the tournament or how many stains I received on my cheerleading uniform.\n",
      " I will love you if I never see you again, and I will love you if I see you every Tuesday.\n",
      " I will love you if you cut your hair and I will love you if you cut the hair of others.\n",
      " I will love you if you abandon your baticeering, and I will love you if you retire from the theater to take up some other, less dangerous occupation.\n",
      " I will love you if you drop your raincoat on the floor instead of hanging it up and I will love you if you betray your father.\n",
      " I will love you even if you announce that the poetry of Edgar Guest is the best in the world and even if you announce that the work of Zilpha Keatley Snyder is unbearably tedious.\n",
      " I will love you if you abandon the theremin and take up the harmonica and I will love you if you donate your marmosets to the zoo and your tree frogs to M.\n",
      " I will love you as the starfish loves a coral reef and as kudzu loves trees, even if the oceans turn to sawdust and the trees fall in the forest without anyone around to hear them.\n",
      " I will love you as the pesto loves the fetuccini and as the horseradish loves the miyagi, as the tempura loves the ikura and the pepperoni loves the pizza.\n",
      " I will love you as the manatee loves the head of lettuce and as the dark spot loves the leopard, as the leech loves the ankle of a wader and as a corpse loves the beak of the vulture.\n",
      " I will love you as the doctor loves his sickest patient and a lake loves its thirstiest swimmer.\n",
      " I will love you as the beard loves the chin, and the crumbs love the beard, and the damp napkin loves the crumbs, and the precious document loves the dampness in the napkin, and the squinting eye of the reader loves the smudged print of the document, and the tears of sadness love the squinting eye as it misreads what is written.\n",
      " I will love you as the iceberg loves the ship, and the passengers love the lifeboat, and the lifeboat loves the teeth of the sperm whale, and the sperm whale loves the flavor of naval uniforms.\n",
      " I will love you as a child loves to overhear the conversations of its parents, and the parents love the sound of their own arguing voices, and as the pen loves to write down the words these voices utter in a notebook for safekeeping.\n",
      " I will love you as a shingle loves falling off a house on a windy day and striking a grumpy person across the chin, and as an oven loves malfunctioning in the middle of roasting a turkey.\n",
      " I will love you as an airplane loves to fall from a clear blue sky and as an escalator loves to entangle expensive scarves in its mechanisms.\n",
      " I will love you as a wet paper towel loves to be crumpled into a ball and thrown at a bathroom ceiling and an eraser loves to leave dust in the hairdos of the people who talk too much.\n",
      " I will love you as a cufflink loves to drop from its shirt and explore the party for itself and as a pair of white gloves loves to slip delicately into the punchbowl.\n",
      " I will love you as a taxi loves the muddy splash of a puddle and as a library loves the patient tick of a clock.\n",
      " I will love you as a thief loves a gallery and as a crow loves a murder, as a cloud loves bats and as a range loves braes.\n",
      " I will love you as misfortune loves orphans, as fire loves innocence and as justice loves to sit and watch while everything goes wrong.\n",
      " I will love you as a battlefield loves young men and as peppermints love your allergies, and I will love you as the banana peel loves the shoe of a man who was just struck by a shingle falling off a house.\n",
      " I will love you as a volunteer fire department loves rushing into burning buildings and as burning buildings love to chase them back out, and as a parachute loves to leave a blimp and as a blimp operator loves to chase after it.\n",
      " I will love you as a dagger loves a certain personâ€™s back, and as a certain person loves to wear daggerproof tunics, and as a daggerproof tunic loves to go to a certain dry cleaning facility, and how a certain employee of a dry cleaning facility loves to stay up late with a pair of binoculars, watching a dagger factory for hours in the hopes of catching a burglar, and as a burglar loves sneaking up behind people with binoculars, suddenly realizing that she has left her dagger at home.\n",
      " I will love you as a drawer loves a secret compartment, and as a secret compartment loves a secret, and as a secret loves to make a person gasp, and as a gasping person loves a glass of brandy to calm their nerves, and as a glass of brandy loves to shatter on the floor, and as the noise of glass shattering loves to make someone else gasp, and as someone else gasping loves a nearby desk to lean against, even if leaning against it presses a lever that loves to open a drawer and reveal a secret compartment.\n",
      " I will love you until all such compartments are discovered and opened, and until all the secrets have gone gasping into the world.\n",
      " I will love you until all the codes and hearts have been broken and until every anagram and egg has been unscrambled.\n",
      " I will love you until every fire is extinguished and until every home is rebuilt form the handsomest and most susceptible of woods, and until every criminal is handcuffed by the laziest of policemen.\n",
      " I will love you until M.\n",
      " hates snakes and J.\n",
      " hates grammar, and I will love you until C.\n",
      " realizes S.\n",
      " is not worthy of his love and N.\n",
      " realizes he is not worthy of the V.\n",
      " I will love you until the bird hates a nest and the worm hates an apple, and until the apple hates a tree and the tree hates a nest, and until a bird hates a tree and an apple hates a nest, although honestly I cannot imagine that last occurrence no matter how hard I try.\n",
      " I will love you as we grow older, which has just happened, and has happened again, and happened several days ago, continuously, and then several years before that, and will continue to happen as the spinning hands of every clock and the flipping pages of every calendar mark the passage of time, except for the clocks that people have forgotten to wind and the calendars that people have forgotten to place in a highly visible area.\n",
      " I will love you as we find ourselves farther and farther from one another, where once we were so close that we could slip the curved straw, and the long, slender spoon, between our lips and fingers respectively.\n",
      " I will love you until the chances of us running into one another slip from skim to zero, and until your face is fogged by distant memory, and your memory faced by distant fog, and your fog memorized by a distant face, and your distance distanced by the memorized memory of a foggy fog.\n",
      " I will love you no matter where you go and who you see, no matter where you avoid and who you donâ€™t see, and no matter who sees you avoiding where you go.\n",
      " I will love you no matter what happens to you, and no matter how I discover what happens to you, and no matter what happens to me as I discover this, and no matter how I am discovered after what happens to me happens to me as I am discovering this.\n",
      " I will love you if you donâ€™t marry me.\n",
      " I will love you if you marry someone else â€“ your co-star, perhaps, or Y.\n",
      ", or even O.\n",
      ", or anyone Z.\n",
      " through A.\n",
      ", even R.\n",
      " although sadly I believe it will be quite some time before two women can be allowed to marry â€“ and I will love you if you have a child, and I will love you if you have two children, or three children, or even more, although I personally think three is plenty, and I will love you if you never marry at all, and never have children, and spend your years wishing you had married me after all, and I must say that on late, cold nights I prefer this scenario out of all the scenarios I have mentioned.\n",
      " That, Beatrice, is how I will love you even as the world goes on its wicked way.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the content of the file\n",
    "text = open(\"the_beatrice_letters.txt\").read()\n",
    "\n",
    "formatted_text = text.replace(\".\", \".\\n\")\n",
    "\n",
    "print(formatted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f6cf43d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will love you until all the codes and hearts have been broken and until every anagram and egg has been unscrambled.\n",
      "I will love you no matter what happens to you, and no matter how I discover what happens to you, and no matter what happens to me as I discover this, and no matter how I am discovered after what happens to me happens to me as I am discovering this.\n",
      "I will love you as a thief loves a gallery and as a crow loves a murder, as a cloud loves bats and as a range loves braes.\n",
      "hates snakes and J.\n",
      "realizes S.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "text = open(\"the_beatrice_letters.txt\").read()\n",
    "\n",
    "sentences = text.split(\".\")\n",
    "\n",
    "sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n",
    "\n",
    "random_sentences = random.sample(sentences, min(5, len(sentences)))\n",
    "\n",
    "for sentence in random_sentences:\n",
    "    print(sentence.strip() + \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b0f0edda",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_word = 'spaceship'\n",
    "factor = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "17e272ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6622d432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will delights you as a spacecraft wonderful to unload from its backpack and discoveries the opposition for itself and as a spaceship of coloured shields delight to tipping delicately into the maneuvers.\n",
      "I will lovin you until the planets of us swapping into one another tripping from spacecraft to zero, and until your shoulders is trapped by spacecraft spaceship, and your rover surfaced by distant fog, and your debra reflecting by a spacecraft shoulders, and your positioning positioning by the approaching starship of a foggy debris.\n",
      "through A.\n",
      "I will lovin you even if you confirm that the writings of Edgar Guest is the ideally in the planets and even if you confirming that the locating of Zilpha Keatley Snyder is unbearably floating.\n",
      "I will loving you as the waters beautiful the spinning of carrots and as the lighten spot beauties the comets, as the leech delight the buckle of a hunter and as a comets delights the spacecraft of the nativity.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "\n",
    "output = []\n",
    "\n",
    "for token in doc:\n",
    "    if token.is_alpha and token.pos_ in ('NOUN', 'VERB', 'ADJ'):\n",
    "        # If the token is alphabetic and its part of speech is NOUN, VERB, or ADJ\n",
    "        # Find the nearest word in the vector space using lookup.nearest()\n",
    "        new_word = random.choice(\n",
    "            lookup.nearest((token.vector * (1 - factor)) + (vec(target_word) * factor), 5))\n",
    "        output.append(new_word)\n",
    "    else:\n",
    "        output.append(token.text)\n",
    "    output.append(token.whitespace_)\n",
    "\n",
    "modified_text = ''.join(output)\n",
    "\n",
    "sentences = modified_text.split(\".\")\n",
    "\n",
    "sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n",
    "\n",
    "random_sentences = random.sample(sentences, min(5, len(sentences)))\n",
    "\n",
    "for sentence in random_sentences:\n",
    "    print(sentence.strip() + \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "333b4499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['love',\n",
       " 'loved',\n",
       " 'lover',\n",
       " 'beau',\n",
       " 'muse',\n",
       " 'laughter',\n",
       " 'dreams',\n",
       " 'admire',\n",
       " 'joy',\n",
       " 'bliss',\n",
       " 'joyful',\n",
       " 'joys']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup.nearest(vec(\"love\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b09070dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pearl',\n",
       " 'ruby',\n",
       " 'ivory',\n",
       " 'apis',\n",
       " 'jade',\n",
       " 'pearls',\n",
       " 'jewel',\n",
       " 'diamond',\n",
       " 'sapphire',\n",
       " 'opal',\n",
       " 'diamonds',\n",
       " 'cara']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup.nearest(vec(\"ruby\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "62775791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sapphire will beau we no matter what is served in the worldâ€™s cafeterias or what game is played at each and every recess.\n",
      "sapphire will beau we with no regard to the actions of our enemies or the jealousies of actors.\n",
      "although sadly sapphire believe it will be quite some time before two women can be allowed to marry â€“ and sapphire will beau we if we have a child, and sapphire will beau we if we have two children, or three children, or even more, although sapphire personally think three is plenty, and sapphire will beau we if we never marry at all, and never have children, and spend wer years wishing we had married me after all, and sapphire must say that on late, cold nights sapphire prefer this scenario out of all the scenarios sapphire have mentioned.\n",
      "sapphire will beau we until all the codes and hearts have been broken and until every anagram and egg has been unscrambled.\n",
      "sapphire will beau we as a dagger beaus a certain personâ€™s back, and as a certain person beaus to wear daggerproof tunics, and as a daggerproof tunic beaus to go to a certain dry cleaning facility, and how a certain employee of a dry cleaning facility beaus to stay up late with a pair of binoculars, watching a dagger factory for hours in the hopes of catching a burglar, and as a burglar beaus sneaking up behind people with binoculars, suddenly realizing that she has left her dagger at home.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "text = open(\"the_beatrice_letters.txt\").read()\n",
    "\n",
    "sentences = text.split(\".\")\n",
    "\n",
    "sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n",
    "\n",
    "random_sentences = random.sample(sentences, min(5, len(sentences)))\n",
    "\n",
    "nearest_words_to_marry = lookup.nearest(vec(\"marry\"))\n",
    "nearest_words_to_ruby = lookup.nearest(vec(\"ruby\"))\n",
    "nearest_words_to_insomnia = lookup.nearest(vec(\"insomnia\"))\n",
    "\n",
    "\n",
    "modify_words = {\n",
    "    \"I\": random.choice(nearest_words_to_ruby),\n",
    "    \"love\": random.choice(nearest_words_to_love),\n",
    "    \"you\": random.choice(nearest_words_to_you),\n",
    "}\n",
    "\n",
    "for sentence in random_sentences:\n",
    "\n",
    "    modified_sentence = sentence\n",
    "    for word, replacement in modify_words.items():\n",
    "        modified_sentence = modified_sentence.replace(word, replacement)\n",
    "    print(modified_sentence.strip() + \".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f98b519e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will love you until the chances of us running into one another slip from skim to zero, and until your face is diamondged by distant memory, and your memory faced by distant diamond, and your diamond memorized by a distant face, and your distance distanced by the memorized memory of a diamondgy diamond.\n",
      ", or anyone pearls.\n",
      "I will love you if you drop your diamonds on the floor instead of hanging it up and I will love you if you betray your father.\n",
      "I will love you until all such compartments are discovered and opened, and until all the ruby have gone gasping into the world.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "text = open(\"the_beatrice_letters.txt\").read()\n",
    "\n",
    "sentences = text.split(\".\")\n",
    "\n",
    "sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n",
    "\n",
    "random_sentences = random.sample(sentences, min(5, len(sentences)))\n",
    "\n",
    "nearest_words_to_apple = lookup.nearest(vec(\"apple\"))\n",
    "\n",
    "\n",
    "for sentence in random_sentences:\n",
    "    doc = nlp(sentence)\n",
    "    nouns = [token.text for token in doc if token.pos_ == \"NOUN\"]\n",
    "    if nouns:\n",
    "        random_noun = random.choice(nouns)\n",
    "        replacement_word = random.choice(nearest_words_to_ruby)\n",
    "        modified_sentence = sentence.replace(random_noun, replacement_word)\n",
    "        print(modified_sentence.strip() + \".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368387bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
